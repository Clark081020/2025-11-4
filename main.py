import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
# pip install koreanize-matplotlib ì„ ì‹¤í–‰í–ˆë‹¤ë©´
import koreanize_matplotlib
import numpy as np # ì˜ˆì‹œ ë°ì´í„° ìƒì„±ì„ ìœ„í•´ ì¶”ê°€

# 1. ì•± ê¸°ë³¸ ì„¤ì •
st.set_page_config(layout="wide")
st.title("ëœë¤ í¬ë ˆìŠ¤íŠ¸ ë¶„ë¥˜ ëª¨ë¸ ì›¹ ì•± ğŸŒ³")
st.markdown("---")

# 2. ë°ì´í„° ë¡œë”© (ì‹¤ì œ ì•±ì—ì„œëŠ” st.file_uploaderë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìê°€ íŒŒì¼ì„ ì˜¬ë¦¬ë„ë¡ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.)
@st.cache_data
def load_data():
    # ì‹¤ì œ ë°ì´í„°ë¥¼ ëŒ€ì‹ í•˜ì—¬ ì˜ˆì‹œ ë°ì´í„°(Iris datasetê³¼ ìœ ì‚¬)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    data = {
        'Feature_A': np.random.rand(150) * 5,
        'Feature_B': np.random.rand(150) * 4,
        'Feature_C': np.random.rand(150) * 6,
        'Target': np.random.randint(0, 3, 150) # 3ê°œì˜ í´ë˜ìŠ¤
    }
    df = pd.DataFrame(data)
    return df

df = load_data()

# 3. ì‚¬ì´ë“œë°” - ì‚¬ìš©ì ì…ë ¥ ë° ëª¨ë¸ ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ëª¨ë¸ ì„¤ì • ë° ì˜ˆì¸¡")

    # A. ëª¨ë¸ ì„¤ì • íŒŒë¼ë¯¸í„°
    n_estimators = st.slider('ê²°ì • ë‚˜ë¬´ ê°œìˆ˜ (n_estimators)', 10, 200, 100)
    max_depth = st.slider('ìµœëŒ€ ê¹Šì´ (max_depth)', 2, 10, 5)

    # B. ì˜ˆì¸¡ì„ ìœ„í•œ ì‚¬ìš©ì ì…ë ¥ê°’ (4ê°œì˜ íŠ¹ì„± columnsì„ ê°€ì •)
    st.subheader("ìƒˆë¡œìš´ ë°ì´í„° ì…ë ¥")
    input_a = st.number_input('íŠ¹ì„± A ê°’', min_value=0.0, max_value=10.0, value=df['Feature_A'].mean())
    input_b = st.number_input('íŠ¹ì„± B ê°’', min_value=0.0, max_value=10.0, value=df['Feature_B'].mean())
    input_c = st.number_input('íŠ¹ì„± C ê°’', min_value=0.0, max_value=10.0, value=df['Feature_C'].mean())

# 4. ë°ì´í„° ì „ì²˜ë¦¬ ë° ëª¨ë¸ í›ˆë ¨
X = df.drop('Target', axis=1)
y = df['Target']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# ëª¨ë¸ í›ˆë ¨ ë° ìºì‹± (íŒŒë¼ë¯¸í„°ê°€ ë°”ë€Œì§€ ì•Šìœ¼ë©´ ì¬í›ˆë ¨ ë°©ì§€)
@st.cache_resource
def train_model(X_train, y_train, n_estimators, max_depth):
    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)
    model.fit(X_train, y_train)
    return model

model = train_model(X_train, y_train, n_estimators, max_depth)
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

# 5. ë©”ì¸ í™”ë©´ ì¶œë ¥
st.header("ğŸ“Š ë¶„ì„ ê²°ê³¼ ë° ëª¨ë¸ ì„±ëŠ¥")

col1, col2 = st.columns(2)

with col1:
    st.subheader("ëª¨ë¸ ì„±ëŠ¥ í‰ê°€")
    st.metric(label="Accuracy (ì •í™•ë„)", value=f"{accuracy:.4f}")
    
    st.text("Classification Report:")
    report_dict = classification_report(y_test, y_pred, output_dict=True)
    report_df = pd.DataFrame(report_dict).transpose()
    st.dataframe(report_df)

with col2:
    st.subheader("í˜¼ë™ í–‰ë ¬ (Confusion Matrix) ì‹œê°í™”")
    cm = confusion_matrix(y_test, y_pred)
    
    fig, ax = plt.subplots()
    cax = ax.matshow(cm, cmap=plt.cm.Blues)
    plt.title('í˜¼ë™ í–‰ë ¬', fontsize=15)
    fig.colorbar(cax)
    
    # ìˆ«ì í‘œì‹œ
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, cm[i, j], va='center', ha='center', color='black' if cm[i, j] < cm.max()/2 else 'white')
            
    ax.set_xlabel('ì˜ˆì¸¡ í´ë˜ìŠ¤', fontsize=12)
    ax.set_ylabel('ì‹¤ì œ í´ë˜ìŠ¤', fontsize=12)
    
    st.pyplot(fig) # Streamlitì— Matplotlib ê·¸ë˜í”„ í‘œì‹œ

st.markdown("---")

# 6. ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ
st.header("ğŸ¯ ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡")

# ì‚¬ìš©ì ì…ë ¥ê°’ìœ¼ë¡œ DataFrame ìƒì„±
new_data = pd.DataFrame({
    'Feature_A': [input_a],
    'Feature_B': [input_b],
    'Feature_C': [input_c]
})

# ì˜ˆì¸¡
prediction = model.predict(new_data)[0]
prediction_proba = model.predict_proba(new_data)[0]

# ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥
st.success(f"ì…ë ¥ê°’: A={input_a:.2f}, B={input_b:.2f}, C={input_c:.2f}")
st.success(f"**ëª¨ë¸ì˜ ì˜ˆì¸¡ í´ë˜ìŠ¤:** **{prediction}**")

# í™•ë¥  ì‹œê°í™”
st.subheader("í´ë˜ìŠ¤ë³„ ì˜ˆì¸¡ í™•ë¥ ")
proba_df = pd.DataFrame({
    'Class': y.unique(),
    'Probability': prediction_proba
}).sort_values('Class')

st.bar_chart(proba_df.set_index('Class'))
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

# koreanize_matplotlib ëŒ€ì‹  ì‚¬ìš©í•  ì½”ë“œ
# í°íŠ¸ íŒŒì¼ì„ í”„ë¡œì íŠ¸ í´ë”ì— ì €ì¥í–ˆë‹¤ê³  ê°€ì •
fontpath = 'NanumGothic.ttf' 
font_name = fm.FontProperties(fname=fontpath, size=10).get_name()
plt.rc('font', family=font_name)
plt.rcParams['axes.unicode_minus'] = False # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€
